{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install langchain openai tiktoken\n",
        "!pip install lancedb\n",
        "!pip install pypdf"
      ],
      "metadata": {
        "id": "aro9oBPnAJbc"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import getpass\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Enter Your OpenAI API Key:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Z1DIiA3qoZe",
        "outputId": "9ee86d1a-f4e1-4873-f989-78404620a1ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter Your OpenAI API Key:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# download the book for producing same results\n",
        "https://www.gita-society.com/bhagavad-gita-in-english-source-file.pdf"
      ],
      "metadata": {
        "id": "2eY0EqQ09Pr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Introducing Hypothetical Document Embeddings (HyDE): A Game-Changer in Zero-Shot Dense Retrieval**\n",
        "\n",
        "The world of information retrieval is witnessing a significant leap forward with the advent of Hypothetical Document Embeddings (HyDE). This breakthrough, developed by a team of researchers, addresses the longstanding challenge of effective zero-shot dense retrieval in the absence of relevance labels. Let's delve into what makes HyDE a revolutionary approach in the field of information retrieval.\n",
        "\n",
        "**The Challenge in Traditional Dense Retrieval**\n",
        "\n",
        "Traditionally, dense retrieval methods have depended heavily on relevance labels to retrieve documents. These labels are crucial for training systems to understand and match semantic similarities between queries and documents. However, this dependency becomes a significant hurdle, especially in scenarios lacking a large, labeled dataset for training. This is where the concept of zero-shot dense retrieval comes into play - a domain that, until now, remained a considerable challenge.\n",
        "\n",
        "**What is HyDE?**\n",
        "\n",
        "HyDE stands out as an innovative solution to this problem. It's an embedding technique that fundamentally changes the retrieval process. Given a query, HyDE uses a language model to generate a hypothetical document. This document, while not real and possibly containing inaccuracies, captures essential relevance patterns to the query.\n",
        "\n",
        "**The Process of HyDE**\n",
        "\n",
        "The magic of HyDE begins with feeding a query into a generative model. The instruction is simple yet powerful: \"write a document that answers this question.\" The result is a hypothetical document that, despite not being real, encapsulates the essence of the query's relevance.\n",
        "The Novelty of Hypothetical Document Embedding\n",
        "HyDE doesn't generate any actual text content for the hypothetical document. Instead, it creates an embedding vector for this \"fake\" document. This vector is crucial as it reserves space in the vector store index but doesn't provide accessible full text. The generated embedding vector is then used to search against the corpus embeddings. The most similar real documents to this embedding are retrieved, making HyDE a novel approach in the field.\n",
        "\n",
        "**Semantic Similarity: The Core Idea**\n",
        "The core idea behind HyDE is that a hypothetical answer to a question is more semantically similar to the actual answer than the question itself. In practical terms, this means your search would use a generative model like GPT to create a hypothetical answer, embed it, and then use this embedding for the search.\n",
        "\n",
        "\n",
        "**Implementing HyDE in LangChain**\n",
        "\n",
        "To utilize HyDE effectively, one needs to provide a base embedding model and an LLMChain for generating documents. The HyDE class comes with default prompts, but there's also the flexibility to create custom prompts. This adaptability makes HyDE not just a tool but a versatile framework adaptable to various needs and scenarios."
      ],
      "metadata": {
        "id": "LSOhF1qzrf88"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.chains import LLMChain, HypotheticalDocumentEmbedder\n",
        "from langchain.prompts import PromptTemplate"
      ],
      "metadata": {
        "id": "2IuHbmcwtd_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# instantiate llm\n",
        "llm = OpenAI()\n",
        "emebeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "phSV35Retf-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HypotheticalDocumentEmbedder.from_llm(llm, emebeddings, \"web_search\")\n",
        "\n",
        "# Now we can use it as any embedding class\n",
        "result = embeddings.embed_query(\"What bhagavad gita tell us?\")\n"
      ],
      "metadata": {
        "id": "-BL8g-E-vpm7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Multiple generations\n",
        "\n",
        "We can also generate multiple documents and then combine the embeddings for those. By default, we combine those by taking the average. We can do this by changing the LLM we use to generate documents to return multiple things.\n"
      ],
      "metadata": {
        "id": "NQMSmzVnvp0E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "multi_llm = OpenAI(n=3, best_of=3)"
      ],
      "metadata": {
        "id": "2SIcCeWUvp6W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HypotheticalDocumentEmbedder.from_llm(\n",
        "    multi_llm, embeddings, \"web_search\"\n",
        ")"
      ],
      "metadata": {
        "id": "owAVG5JtwDWF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result = embeddings.embed_query(\"What bhagavad gita tell us?\")"
      ],
      "metadata": {
        "id": "i54keBy8wEXG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `HypotheticalDocumentEmbedder` does not actually create full hypothetical documents.\n",
        "\n",
        "It only generates an embedding vector representing a hypothetical document.\n",
        "\n",
        "The `HypotheticalDocumentEmbedder` is used to generate \"dummy\" embeddings that can be inserted into a vectorstore index.\n",
        "\n",
        "This allows you to reserve space for documents that don't exist yet, so that you can incrementally add new real documents later.\n",
        "\n",
        "But the embedder itself does not generate any actual text content for these hypothetical documents.\n",
        "\n",
        "It simply generates an embedding vector using a strategy like sampling from a normal distribution."
      ],
      "metadata": {
        "id": "WGxLiMKRJF6v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Making Your Own Prompts\n",
        "You can also make and use your own prompts when creating documents with LLMChain. This is helpful if you know what topic you're asking about. With a custom prompt, you can get text that fits your topic better.\n",
        "\n",
        "Let's try this out. We'll make a prompt about a state of the union address, which we'll use in the next example."
      ],
      "metadata": {
        "id": "mS8CgXqmwKpz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"\n",
        "As a knowledgeable and helpful research assistant, your task is to provide informative answers based on the given context. Use your extensive knowledge base to offer clear, concise, and accurate responses to the user's inquiries.\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "prompt = PromptTemplate(input_variables=[\"question\"], template=prompt_template)\n",
        "\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "_Xkvn9_d-3pU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings = HypotheticalDocumentEmbedder(\n",
        "    llm_chain=llm_chain,\n",
        "    base_embeddings=embeddings\n",
        ")"
      ],
      "metadata": {
        "id": "dZ5gPHYW--32"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading data from pdf"
      ],
      "metadata": {
        "id": "fj8Dzu1UvHUp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "#Load the  multiple pdfs\n",
        "pdf_folder_path = '/content/book'\n",
        "\n",
        "from langchain.document_loaders import PyPDFDirectoryLoader\n",
        "loader = PyPDFDirectoryLoader(pdf_folder_path)\n",
        "docs = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=500,\n",
        "    chunk_overlap=50,\n",
        ")\n",
        "documents = text_splitter.split_documents(docs)\n"
      ],
      "metadata": {
        "id": "JpSOGkpTAbpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import LanceDB\n",
        "import lancedb\n",
        "\n",
        "# lancedb as vectorstore\n",
        "db = lancedb.connect('/tmp/lancedb')\n",
        "table = db.create_table(\"documentsai\", data=[\n",
        "    {\"vector\": embeddings.embed_query(\"Hello World\"), \"text\": \"Hello World\", \"id\": \"1\"}\n",
        "], mode=\"overwrite\")\n",
        "vector_store = LanceDB.from_documents(documents, embeddings, connection=table)\n"
      ],
      "metadata": {
        "id": "rXFIs5v7Abt3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# passing in the string query to get some refrence\n",
        "query = \"What is karma -yoga  ?\"\n",
        "\n",
        "vector_store.similarity_search(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4bvTDFDEEX6",
        "outputId": "26a97423-edd6-46c2-bbe6-efbaeeb44848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='gaged in work, such a Karma -yogi is not bound by Karma. (4.22) \\nThe one who is free f rom attachment, whose mind is fixed in Self -\\nknowledge, who does work as a service (Sev a) to the Lord, all K ar-\\nmic bonds of such a philanthropic person ( Karma -yogi) dissolve \\naway. (4.23) God shall be realized by the one who considers eve-\\nrything as a manifest ation or an act of God. (Also see 9.16) (4.24)  \\nDifferent types of spiritual practices', metadata={'vector': array([-0.00885663, -0.01420569,  0.00011372, ..., -0.02555135,\n",
              "         0.01844176, -0.03537256], dtype=float32), 'id': '073ebe84-0eac-444e-9547-1fdc17f568ed', '_distance': 0.22069776058197021}),\n",
              " Document(page_content='the best of your ability, O Arjuna, with your mind attached to the \\nLord, aba ndoning worry and attachment  to the results, and remain-\\ning calm in both success and failure. The calmness of mind  is \\ncalled Karma -yoga . (2.48) Work done with selfish motives is infe-\\nrior by far to selfless service or Karma -yoga . Therefore, be a \\nKarma -yogi, O Arjuna. Those who work only to enjoy the fruits of \\ntheir labor are, in truth, unhappy. Because , one has no control over \\nthe results. (2.49)', metadata={'vector': array([ 0.00595851, -0.01140496,  0.01743662, ..., -0.01557459,\n",
              "         0.0079868 , -0.03753329], dtype=float32), 'id': '5fa4918c-dee8-4404-8d41-50736ae236e5', '_distance': 0.2241656482219696}),\n",
              " Document(page_content='renunciation (Samny asa) is also known as Karma -yoga . No one \\nbecomes a Karma -yogi who has not renounced the selfish motive \\nbehind an action. (6.02)  \\nA definition of yoga and yogi  \\nFor the wise who seeks to attain yoga of meditation or calm-\\nness of mind, Karma -yoga  is said to be the means. For the one \\nwho has attained yoga, the calmness becomes the means of Self -\\nrealization. A person is said to have attained yogic perfection when', metadata={'vector': array([ 0.00469063, -0.02185667,  0.01842017, ...,  0.00019575,\n",
              "         0.01339708, -0.02466117], dtype=float32), 'id': '80ecd164-ae70-43e5-8482-1ef7008678aa', '_distance': 0.23700472712516785}),\n",
              " Document(page_content='are operating upon their objects. (5.08 -09) One who does all work \\nas an offering to the Lord — abandoning attachment  to the results \\n— remains untouched by K armic reaction or sin as a lotus leaf \\nnever gets wet by water , while living in it . (5.10) The Karma -yogis \\nperform action —without attachment  — with their body, mind, in-\\ntellect, and senses only for self -purification. (5.11) A Karma -yogi \\nattains Supreme Bliss by abandoning attachment to the fruits of', metadata={'vector': array([-0.01593315, -0.01162167,  0.00489879, ..., -0.00652251,\n",
              "         0.00487806, -0.04383345], dtype=float32), 'id': '7f18aef0-86bd-456f-8f57-3ca2157dbb5b', '_distance': 0.23891010880470276})]"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.run(\"tell me 10 key points from this book bhagavad gita\")"
      ],
      "metadata": {
        "id": "aJ-scBC0qCOx",
        "outputId": "7bcde720-859b-4912-add6-9bae988dd68e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1. We are all connected to the divine and should strive to realize this connection.\\n2. Our actions in life should be guided by dharma, or right conduct.\\n3. We should strive to be free from attachment and selfish desires.\\n4. We should strive to control our senses and mind.\\n5. We should strive to remain dedicated to our spiritual path.\\n6. We should focus on the present and not be swayed by the past or future.\\n7. We should strive to live a balanced life of moderation.\\n8. We should always strive to do our utmost duty.\\n9. We should strive to develop our inner spiritual power.\\n10. We should strive to surrender to the divine will.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.run(\"explain the karma & its impact \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "mpwEO-xSFQvL",
        "outputId": "d3e681f0-9fe9-4bdf-8135-ad1a8dcf3d94"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Karma is a spiritual concept in Hinduism, Buddhism, Jainism, Sikhism, and Taoism which suggests that the actions of an individual (as well as the intentions behind those actions) have an effect on the future of that individual. It is believed that good deeds result in favourable karma, while bad deeds result in bad karma. The impact of karma can be seen in many aspects of life, including relationships, health, success, and overall wellbeing.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.run(\"who is yogi ?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "0wqAiynUHXZG",
        "outputId": "fb337122-ca7a-4dd3-8731-077ef2714b91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yogi is a bear character created by Hanna-Barbera who first appeared in 1958. He is a brown bear who likes to talk in rhyme and is known for his catchphrase \"Hey, Boo Boo!\". He is best friends with his sidekick, Boo Boo.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.run(\"what are the 3 models of nature?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "QfUGLjr8HhIr",
        "outputId": "cc7bc62b-dc22-4145-862f-2505a5696298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The three models of nature are the mechanistic model, the organismic model, and the ecosystemic model. The mechanistic model views nature as an inanimate system of parts. The organismic model views nature as a living organism. The ecosystemic model views nature as an interconnected web of living and nonliving components.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm_chain.run(\"what is god \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "C3UvnY6YIKxf",
        "outputId": "76b99c1c-9e16-4e45-9748-db6a7843acfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'God is traditionally understood as a supernatural being who is all-knowing, all-powerful, and the creator of the universe. Different religions and cultures have different beliefs about the nature of God.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pAkgNtzCIOyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Lluogzuifkcy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}